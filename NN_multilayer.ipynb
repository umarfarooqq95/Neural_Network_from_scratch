{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Sabudh\\MNIST\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Sabudh\\MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\"\n",
    "    size: Number of nodes in the hidden layer \n",
    "    activation: name of activation function for the layer\n",
    "    \"\"\"\n",
    "    def __init__(self,size,activation='sigmoid'): \n",
    "        self.shape=(1,size)\n",
    "        self.activation=activation\n",
    "                \n",
    "class NeuralNetwork():\n",
    "    def __init__(self,x,y):\n",
    "        \"\"\"\n",
    "        x is 2d array of input images\n",
    "        y are one hot encoded labels \n",
    "        \"\"\"\n",
    "        self.x=x/255   # Divide by 255 to normalise the pixel values (0-255)\n",
    "        self.y=y\n",
    "        self.weights=[]\n",
    "        self.outputs=[]\n",
    "        self.derivatives=[]\n",
    "        self.activations=[]\n",
    "        self.delta_weights=[]\n",
    "        \n",
    "    def connect(self,layer1,layer2):\n",
    "        \"\"\"layer 2 of shape 1xn\"\"\"\n",
    "        #Initialise weights,derivatives and activation lists\n",
    "        self.derivatives.append(np.random.uniform(0,0.1,size=(layer1.shape[1]+1,layer2.shape[1])))\n",
    "        self.weights.append(np.random.uniform(-1,1,size=(layer1.shape[1]+1,layer2.shape[1])))\n",
    "        self.delta_weights.append(np.zeros((layer1.shape[1]+1,layer2.shape[1])))\n",
    "        if isinstance(layer2,Layer):\n",
    "            self.activations.append(layer2.activation)\n",
    "            \n",
    "    def activation(self,name,z,derivative=False):\n",
    "        \n",
    "        #implementation of various activation functions and their derivatives\n",
    "        if name=='sigmoid':\n",
    "            if derivative==False:\n",
    "                return 1/(1+np.exp(-z))\n",
    "            else:\n",
    "                return z*(1-z)\n",
    "        elif name=='relu':\n",
    "            pass\n",
    "        \n",
    "    def softmax(self,z):\n",
    "        e=np.exp(z)\n",
    "        return e/np.sum(e,axis=1).reshape(-1,1) \n",
    "    \n",
    "    def max_log_likelihood(self,y_pred,y):\n",
    "        \"\"\"cross entropy\"\"\"\n",
    "        return y*np.log(y_pred)\n",
    "    \n",
    "    def delta_mll(self,y,y_pred):\n",
    "        \"\"\"derivative of cross entropy\"\"\"\n",
    "        #return y*(y_pred-1)\n",
    "        return y_pred-y\n",
    "    \n",
    "    def forward_pass(self,x,y,weights):\n",
    "        cost=0\n",
    "        self.outputs=[]\n",
    "        for i in range(len(weights)):\n",
    "            samples=len(x)\n",
    "            ones_array=np.ones(samples).reshape(samples,1)\n",
    "            self.outputs.append(x) #append without adding ones array\n",
    "            z=np.dot(np.append(ones_array,x,axis=1),weights[i])\n",
    "            if i==len(weights)-1:\n",
    "                x=self.softmax(z)\n",
    "            else:\n",
    "                x=self.activation(self.activations[i],z)\n",
    "        self.outputs.append(x)\n",
    "        self.y_pred=x\n",
    "        \n",
    "        temp=-self.max_log_likelihood(self.y_pred,y)\n",
    "        cost=np.mean(np.sum(temp,axis=1))\n",
    "        return cost\n",
    "    \n",
    "    \n",
    "    def backward_pass(self,y,step,momentum=False,beta=0.9):\n",
    "        for i in range(len(self.weights)-1,-1,-1):\n",
    "            ones_array=np.ones(len(n.outputs[i])).reshape(len(n.outputs[i]),1)\n",
    "            if i==len(self.weights)-1:\n",
    "                prev_term=self.delta_mll(y,self.y_pred)  \n",
    "                # derivatives follow specific order,last three terms added new,rest from previous term  \n",
    "                self.derivatives[i]=np.dot(prev_term.T,np.append(ones_array,self.outputs[i],axis=1))   \n",
    "            else:\n",
    "                prev_term=np.dot(prev_term,self.weights[i+1][1:].T)*self.activation(self.activations[i],self.outputs[i+1],derivative=True)\n",
    "                self.derivatives[i]=np.dot(prev_term.T,np.append(ones_array,self.outputs[i],axis=1))\n",
    "            if momentum:\n",
    "                self.delta_weights[i]=beta*self.delta_weights[i]-step*((self.derivatives[i].T)/len(y))\n",
    "                self.weights[i]=self.weights[i]+self.delta_weights[i]\n",
    "            else:\n",
    "                self.weights[i]=self.weights[i]-step*((self.derivatives[i].T)/len(y))\n",
    "                \n",
    "    \n",
    "    def train(self,batches,step=1e-3,epoch=10):\n",
    "        \"\"\"number of batches to split data in,step size and epochs\"\"\"\n",
    "        for epochs in range(epoch):\n",
    "            samples=len(self.x)\n",
    "            c=0\n",
    "            for i in range(batches):\n",
    "                x_batch=self.x[int((samples/batches)*i):int((samples/batches)*(i+1))]\n",
    "                y_batch=self.y.loc[int((samples/batches)*i):int((samples/batches)*(i+1))-1]\n",
    "                \n",
    "                c=self.forward_pass(x_batch,y_batch,self.weights)\n",
    "                self.backward_pass(y_batch,step,momentum=True)\n",
    "            print(epochs,c/batches)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        \"\"\"input: x_test values\"\"\"\n",
    "        x=x/255\n",
    "        for i in range(len(self.weights)):\n",
    "            samples=len(x)\n",
    "            ones_array=np.ones(samples).reshape(samples,1)\n",
    "            z=np.dot(np.append(ones_array,x,axis=1),self.weights[i])\n",
    "            if i==len(self.weights)-1:\n",
    "                x=self.softmax(z)\n",
    "            else:\n",
    "                x=self.activation(self.activations[i],z)\n",
    "        #self.y_pred=x\n",
    "        # return index(digit) with highest probability \n",
    "        return np.argmax(x,axis=1)\n",
    "        #return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist data images as X ,labels as Y (Train data)\n",
    "X, Y = loadlocal_mnist(images_path='train-images.idx3-ubyte', labels_path='train-labels.idx1-ubyte')\n",
    "\n",
    "#load mnist data images as x ,labels as y (Test data)\n",
    "x,y=loadlocal_mnist(images_path='t10k-images.idx3-ubyte', labels_path='t10k-labels.idx1-ubyte')\n",
    "\n",
    "#One hot encoding of training labels \n",
    "Labels=pd.get_dummies(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0006290452105615551\n",
      "1 0.0004855376653063454\n",
      "2 0.00042538433851476565\n",
      "3 0.00038778345264871755\n",
      "4 0.00036200951415491547\n",
      "5 0.00034338361992765977\n",
      "6 0.00032803182694229703\n",
      "7 0.00031402587149243876\n",
      "8 0.0003012513615820466\n",
      "9 0.00028987312758038826\n",
      "10 0.0002798709193301331\n",
      "11 0.00027111904912354215\n",
      "12 0.0002635075917120462\n",
      "13 0.000256921607475452\n",
      "14 0.0002511622199604051\n",
      "15 0.00024596912330632925\n",
      "16 0.0002411120417814635\n",
      "17 0.0002364304592246316\n",
      "18 0.00023180362526945038\n",
      "19 0.00022712999497762805\n"
     ]
    }
   ],
   "source": [
    "n=NeuralNetwork(X,Labels)\n",
    "l1=Layer(100)\n",
    "#l2=Layer(100)\n",
    "n.connect(X,l1)\n",
    "#n.connect(l1,l2)\n",
    "n.connect(l1,Labels)\n",
    "n.train(batches=500,step=0.1,epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1012, 1139, 1038, 1005,  981,  920,  932, 1019,  937, 1017],\n",
       "       dtype=int64),\n",
       " array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=n.predict(x)\n",
    "np.bincount(n.predict(x)),np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 96.33 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy is {np.bincount(np.abs(y-pred))[0]*100/len(y)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
